{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aqXYaRXSbzy",
        "outputId": "d3a42b26-8bfe-4bf3-f53a-136785541108"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m76.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics opencv-python-headless pillow --quiet\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> \"Since our prototype uses pre-recorded videos, we simulate timestamps using Python’s datetime module. In live CCTV integrations, this would be replaced with actual frame capture timestamps synced with system time.\""
      ],
      "metadata": {
        "id": "LGpszgNkTJO2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ozb-qS_L95YQ",
        "outputId": "2fa5806c-c17d-49d1-dad6-1fdf2b1958a5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "zip_path = '/content/drive/MyDrive/HACKATHON/cctv_vids.zip'\n",
        "extract_path = '/content/cctv_vids'\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(\" Extracted videos to:\", extract_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-gMZg1M8cNp",
        "outputId": "3f7e7622-b774-4d57-edb5-5926e4db1234"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Extracted videos to: /content/cctv_vids\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# In a real CCTV feed, we can use datetime.now() to timestamp each frame"
      ],
      "metadata": {
        "id": "9tPEYQuXSimd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "# Path where your VIRAT videos are stored\n",
        "video_folder = \"/content/cctv_vids/cctv_vids\"\n",
        "video_files = glob.glob(os.path.join(video_folder, \"*.mp4\"))\n",
        "\n",
        "# Loop through each .mp4 file\n",
        "for video_path in video_files:\n",
        "    video_id = video_path.split(\"/\")[-1].split(\".\")[0]\n",
        "    print(f\"Processing: {video_id}\")\n",
        "\n",
        "  # ⬇️ Call your detection function here\n",
        "     # detect_objects_in_video(video_path, video_id)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DsKqNwEPgNZd",
        "outputId": "e4f89aef-e335-46dc-922e-4417d1f73a5f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing: VIRAT_S_010108_01_000570_000718\n",
            "Processing: VIRAT_S_010207_03_000865_000911\n",
            "Processing: VIRAT_S_000201_06_001354_001397\n",
            "Processing: VIRAT_S_010106_03_000730_000782\n",
            "Processing: VIRAT_S_050301_01_000083_000320\n",
            "Processing: VIRAT_S_010001_03_000537_000563\n",
            "Processing: VIRAT_S_000202_00_000000_000977\n",
            "Processing: VIRAT_S_010000_08_000893_001024\n",
            "Processing: VIRAT_S_050300_10_002176_002238\n",
            "Processing: VIRAT_S_000201_08_001652_001838\n",
            "Processing: VIRAT_S_010107_02_000282_000312\n",
            "Processing: VIRAT_S_050301_00_000000_000036\n",
            "Processing: VIRAT_S_010205_02_000301_000345\n",
            "Processing: VIRAT_S_010205_04_000545_000576\n",
            "Processing: VIRAT_S_010106_02_000656_000692\n",
            "Processing: VIRAT_S_010001_00_000019_000065\n",
            "Processing: VIRAT_S_000201_07_001485_001581\n",
            "Processing: VIRAT_S_010207_02_000790_000816\n",
            "Processing: VIRAT_S_050301_02_000544_000607\n",
            "Processing: VIRAT_S_010001_01_000071_000167\n",
            "Processing: VIRAT_S_000201_05_001081_001215\n",
            "Processing: VIRAT_S_010106_04_000800_000918\n",
            "Processing: VIRAT_S_010205_03_000370_000395\n",
            "Processing: VIRAT_S_010001_02_000195_000498\n",
            "Processing: VIRAT_S_050301_03_000933_001046\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "video_id = video_folder.split(\"/\")[-1].split(\".\")[0]\n",
        "# Example: \"VIRAT_S_050300_03_001789_001858\"\n",
        "# → use as camera ID or location tag"
      ],
      "metadata": {
        "id": "V3lV8IfTTMfD"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")"
      ],
      "metadata": {
        "id": "FuZnyyevT4X3"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4i5PXA3Og6-G",
        "outputId": "73109203-d25a-431c-e34a-59b265ae4583"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: numpy<2.3.0,>=2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (2.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2"
      ],
      "metadata": {
        "id": "mvHhYLQng_21"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "with open(\"frame_logs.csv\", mode='w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"video_id\", \"frame_number\", \"timestamp\"])\n",
        "\n",
        "    for video_path in video_files:\n",
        "        video_id = os.path.basename(video_path).split(\".\")[0]\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        frame_no = 0\n",
        "\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            frame_no += 1\n",
        "            timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "            writer.writerow([video_id, frame_no, timestamp])\n",
        "\n",
        "        cap.release()\n"
      ],
      "metadata": {
        "id": "BZyeFBKkgyzD"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_random_frame(video_folder):\n",
        "    cap = cv2.VideoCapture(video_folder)\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    if total_frames <= 1:\n",
        "        print(f\"empty video: {video_path}\")\n",
        "        return None\n",
        "\n",
        "    rand_frame = random.randint(0, total_frames - 1)\n",
        "    cap.set(cv2.CAP_PROP_POS_FRAMES, rand_frame)\n",
        "    ret, frame = cap.read()\n",
        "    cap.release()\n",
        "\n",
        "    if not ret:\n",
        "        print(f\"Could not read frame from: {video_folder}\")\n",
        "        return None\n",
        "\n",
        "    frame = cv2.resize(frame, (320, 320))  # Resize for mosaic\n",
        "    return frame\n"
      ],
      "metadata": {
        "id": "3iDQHdugkkex"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_paths = glob.glob(os.path.join(video_folder, \"*.mp4\"))\n",
        "\n",
        "# Print the video paths\n",
        "print(\"Found videos:\")\n",
        "for vp in video_paths:\n",
        "    print(vp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4Cl5uQtkrmF",
        "outputId": "22363eb3-c7af-451a-dce9-5e4fa852e4ab"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found videos:\n",
            "/content/cctv_vids/cctv_vids/VIRAT_S_010108_01_000570_000718.mp4\n",
            "/content/cctv_vids/cctv_vids/VIRAT_S_010207_03_000865_000911.mp4\n",
            "/content/cctv_vids/cctv_vids/VIRAT_S_000201_06_001354_001397.mp4\n",
            "/content/cctv_vids/cctv_vids/VIRAT_S_010106_03_000730_000782.mp4\n",
            "/content/cctv_vids/cctv_vids/VIRAT_S_050301_01_000083_000320.mp4\n",
            "/content/cctv_vids/cctv_vids/VIRAT_S_010001_03_000537_000563.mp4\n",
            "/content/cctv_vids/cctv_vids/VIRAT_S_000202_00_000000_000977.mp4\n",
            "/content/cctv_vids/cctv_vids/VIRAT_S_010000_08_000893_001024.mp4\n",
            "/content/cctv_vids/cctv_vids/VIRAT_S_050300_10_002176_002238.mp4\n",
            "/content/cctv_vids/cctv_vids/VIRAT_S_000201_08_001652_001838.mp4\n",
            "/content/cctv_vids/cctv_vids/VIRAT_S_010107_02_000282_000312.mp4\n",
            "/content/cctv_vids/cctv_vids/VIRAT_S_050301_00_000000_000036.mp4\n",
            "/content/cctv_vids/cctv_vids/VIRAT_S_010205_02_000301_000345.mp4\n",
            "/content/cctv_vids/cctv_vids/VIRAT_S_010205_04_000545_000576.mp4\n",
            "/content/cctv_vids/cctv_vids/VIRAT_S_010106_02_000656_000692.mp4\n",
            "/content/cctv_vids/cctv_vids/VIRAT_S_010001_00_000019_000065.mp4\n",
            "/content/cctv_vids/cctv_vids/VIRAT_S_000201_07_001485_001581.mp4\n",
            "/content/cctv_vids/cctv_vids/VIRAT_S_010207_02_000790_000816.mp4\n",
            "/content/cctv_vids/cctv_vids/VIRAT_S_050301_02_000544_000607.mp4\n",
            "/content/cctv_vids/cctv_vids/VIRAT_S_010001_01_000071_000167.mp4\n",
            "/content/cctv_vids/cctv_vids/VIRAT_S_000201_05_001081_001215.mp4\n",
            "/content/cctv_vids/cctv_vids/VIRAT_S_010106_04_000800_000918.mp4\n",
            "/content/cctv_vids/cctv_vids/VIRAT_S_010205_03_000370_000395.mp4\n",
            "/content/cctv_vids/cctv_vids/VIRAT_S_010001_02_000195_000498.mp4\n",
            "/content/cctv_vids/cctv_vids/VIRAT_S_050301_03_000933_001046.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import random\n",
        "import glob\n",
        "import os\n",
        "\n",
        "def get_random_frame(video_folder):\n",
        "    cap = cv2.VideoCapture(video_folder)\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    if total_frames <= 1:\n",
        "        print(f\" Skipping: {os.path.basename(video_folder)} - No frames\")\n",
        "        return None\n",
        "\n",
        "    for _ in range(5):  # Try 5 times to get a valid frame\n",
        "        rand_frame = random.randint(0, total_frames - 1)\n",
        "        cap.set(cv2.CAP_PROP_POS_FRAMES, rand_frame)\n",
        "        ret, frame = cap.read()\n",
        "        if ret:\n",
        "            cap.release()\n",
        "            frame = cv2.resize(frame, (320, 320))\n",
        "            return frame\n",
        "\n",
        "    cap.release()\n",
        "    print(f\" Failed to extract frame from {os.path.basename(video_folder)}\")\n",
        "    return None\n",
        "\n",
        "def apply_augmentation(img):\n",
        "    if img is None:\n",
        "        return np.zeros((320, 320, 3), dtype=np.uint8)\n",
        "\n",
        "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
        "    hsv[..., 2] = np.clip(hsv[..., 2] * random.uniform(0.7, 1.3), 0, 255)\n",
        "    img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
        "\n",
        "    if random.random() > 0.5:\n",
        "        img = cv2.flip(img, 1)\n",
        "\n",
        "    noise = np.random.randint(0, 20, img.shape, dtype='uint8')\n",
        "    img = cv2.add(img, noise)\n",
        "\n",
        "    return img\n",
        "\n",
        "def create_mosaic_from_videos(video_paths):\n",
        "    frames = []\n",
        "    tries = 0\n",
        "    while len(frames) < 4 and tries < 10:\n",
        "        path = random.choice(video_paths)\n",
        "        frame = get_random_frame(path)\n",
        "        if frame is not None:\n",
        "            frames.append(apply_augmentation(frame))\n",
        "        tries += 1\n",
        "\n",
        "    if len(frames) < 4:\n",
        "        raise Exception(\"Not enough valid frames to create mosaic.\")\n",
        "\n",
        "    top = np.hstack((frames[0], frames[1]))\n",
        "    bottom = np.hstack((frames[2], frames[3]))\n",
        "    mosaic = np.vstack((top, bottom))\n",
        "    return mosaic\n",
        "\n",
        "try:\n",
        "    mosaic_img = create_mosaic_from_videos(video_paths)\n",
        "    cv2.imwrite(\"/content/mosaic_from_video.jpg\", mosaic_img)\n",
        "    print(\"Mosaic image saved at /content/mosaic_from_video.jpg\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(str(e))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTjGeUkNk2pT",
        "outputId": "a656fbe8-83cc-427a-f390-4b8f6dc3956a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mosaic image saved at /content/mosaic_from_video.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import glob\n",
        "\n",
        "input_videos = glob.glob(os.path.join(video_folder, \"*.mp4\"))\n",
        "  # Change this path to your actual folder\n",
        "output_folder = \"color_frames_\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "def enhance_color_frame(frame):\n",
        "    # Split the BGR channels\n",
        "    b, g, r = cv2.split(frame)\n",
        "\n",
        "    # Create CLAHE object\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "\n",
        "    # Apply CLAHE to each channel\n",
        "    b_clahe = clahe.apply(b)\n",
        "    g_clahe = clahe.apply(g)\n",
        "    r_clahe = clahe.apply(r)\n",
        "\n",
        "    # Merge the channels back\n",
        "    enhanced = cv2.merge((b_clahe, g_clahe, r_clahe))\n",
        "\n",
        "    # Resize for YOLO if needed\n",
        "    enhanced = cv2.resize(enhanced, (416, 416))\n",
        "\n",
        "    return enhanced\n",
        "\n",
        "def extract_and_enhance(video_paths, video_id):\n",
        "    cap = cv2.VideoCapture(video_paths)\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    frame_indices = [int(total_frames * i / 6) for i in range(1, 6)]  # Take 5 frames\n",
        "    saved = 0\n",
        "\n",
        "    for i in range(total_frames):\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        if i in frame_indices:\n",
        "            enhanced = enhance_color_frame(frame)\n",
        "            filename = f\"{output_folder}/video{video_id}_frame{saved+1}.jpg\"\n",
        "            cv2.imwrite(filename, enhanced)\n",
        "            saved += 1\n",
        "        if saved == 5:\n",
        "            break\n",
        "    cap.release()\n",
        "\n",
        "# Loop through all videos\n",
        "for idx, path in enumerate(input_videos):\n",
        "    extract_and_enhance(path, idx + 1)\n",
        "\n",
        "print(\"Color-enhanced frames saved to:\", output_folder)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhNl9l1Ypydb",
        "outputId": "edc44119-1b92-4ccf-a323-1c2a77e8c31f"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Color-enhanced frames saved to: color_frames_\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Zip the folder (change folder name if needed)\n",
        "shutil.make_archive(\"color_frames_1\", 'zip', \"/content/color_frames_\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "KVR_e6QcMvOj",
        "outputId": "bab42e32-fb7c-4a65-a93b-5628c6924ef9"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/color_frames_1.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Start download\n",
        "files.download(\"color_frames_1.zip\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "nAs25ug4OP3E",
        "outputId": "308e451e-c007-40c0-c80a-fb56baec15e2"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ed6c3777-4a68-40d2-9615-c50dcc014090\", \"color_frames_1.zip\", 13149994)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rLR9dhLDS__z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}